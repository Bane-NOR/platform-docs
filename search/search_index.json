{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Bane NOR External DocumentationWelcome to the Portal!","text":"<p>Welcome to the Bane NOR External Documentation portal! This centralized resource is designed to streamline your access to user guides, FAQs, best practices, and other relevant documentation essential for external users. This portal is your single source of truth for integrating with BaneNOR's platform services.</p> <p>The content is curated for a technical audience, including developers, system architects, and technical specialists working on Bane NOR's three service platforms: Development Platform, Integration Platform, and Data Platform. By consolidating information previously scattered across multiple wikis, we aim to save time, eliminate confusion, and enhance productivity.</p>"},{"location":"#how-to-navigate","title":"How to Navigate","text":"<p>To ensure ease of use, the documentation is organized into three main sections, each dedicated to one of Bane NOR's service platforms:</p> <ol> <li>Integration Platform: Resources for connecting and integrating systems seamlessly.</li> </ol> <p>Each section contains categorized articles, FAQs, and troubleshooting guides, making it easy to find the information relevant to your needs. Additionally, a global search function indexes all content across platforms, so you can locate any document or guide quickly without needing to know where it resides.</p>"},{"location":"#ownership-and-support","title":"Ownership and Support","text":"<p>The portal is maintained and owned by the Data and Development Platform Team. If you encounter issues, have feedback, or need assistance, feel free to reach out to us via Data and Development Platform.</p> <p>Your feedback helps us improve! Let us know how we can enhance your experience or add value to the documentation.</p> <p>This page serves as your gateway to the knowledge base that drives Bane NOR's development, integration, and data services. Explore, learn, and build confidently!</p>"},{"location":"integration/Event-Issuer/","title":"Why Event Issuer exists","text":"<p>The goal of an Event Issuer is to provide an infrastructure to abstract event delivery via a secured RESTful API to external users and systems such as SaaS. This allows external users to maintain service boundaries, and not directly depend on any specific message broker technology. The event issuer will have the possibility to consume events from Bane NOR and produce new events.</p> <p></p>"},{"location":"integration/Event-Issuer/#consumer","title":"Consumer","text":"<p>The consumer side of the Event Issuer is based on webhooks. Webhooks are the foundation for modern API development and is a universal concept that is easily understood by many systems as a way to react to changes.</p> <p>One of the main issues though is contracts, since Event Issuer should handle many different types of events, it is important to use well-defined schemas/contracts that can be used for validation. For this, the Event Issuer can be used to get registered schemas for different events that can be subscribed to.</p>"},{"location":"integration/Event-Issuer/#what-are-webhooks","title":"What are Webhooks?","text":"<p>Webhooks are how one system notifies another system of a state change.</p> <p>In architectural terms, a webhook is a programming language agnostic approach for sending messages between distributed systems. The power of webhooks comes first from being independent of any specific tech stack and second from the notification-based approach. Regardless of your architecture, your systems can receive or broadcast webhooks without being dependent on a specific vendor or even on the same network. Further, downstream systems receiving webhooks don't need to poll a central system for updates or status changes, they can simply listen for an event and process the results.</p> <p>In practical terms, a webhook is simply an HTTP request - usually a POST - with a JSON payload or parameters broadcast from the central system. Much of the modern web is built on this distributed communication pattern.</p>"},{"location":"integration/Event-Issuer/#producing","title":"Producing","text":"<p>To produce events to Bane NOR the Event Issuer will have endpoints that can be used to send new events. These events must have predefined data schemas that will be registered into the schema registry. This gives the Event Issuer the ability to validate incoming events that they are in fact following the contract and do not cause any poison pill to our systems.</p> <p>In Confluent a Poison Pill is defined as:</p> <p>Note</p> <p>\u201ca record that has been produced to a Kafka topic and always fails when consumed, no matter how many times it is attempted.\u201d \u2014 Confluent.io</p>"},{"location":"integration/Event-Issuer/#cloudevents","title":"Cloudevents","text":"<p>A specification for describing event data in a common way - cloudevents.io</p> <p>Cloudevents is part of the Cloud Native Computing Foundation list of projects. This is a specification that tries to standardize the way we describe events and their metadata/headers.</p> <p>Event Issuer follows the cloudevents specification and will and uses the HTTP protocol bindings for all outgoing events. For producers, this will be based on the JSON Event Format.</p> <p>For more technical specifications see the cloudevents user guide section</p>"},{"location":"integration/Event-Issuer/#security","title":"Security","text":"<p>Event Issuer will go through some different phases regarding security where the initial alpha versions will only work for invited partners. We will work towards the consumer side to be self-service for the most part, where producers need to be controlled before they are allowed to send events.</p> <p>It is also important to support different authentication and authorizations not only to Bane NOR but also to external webhooks.</p> <p>Some ideas for features that will be looked into and added are:</p> <ul> <li>OAuth2, JWTs, and JWKs for authentication and authorization towards the webhook endpoint</li> <li>API Keys that can be configured by the end users if needed to authenticate to their webhook endpoints</li> <li>One Time Verification, seen at other systems like Twitter and Microsoft OneDrive. Use during setup to confirm that the consumer controls the code endpoint</li> <li>Event signing so that consumer can verify that the event has not been tampered with after being sent from Event Issuer and gives event integrity</li> </ul>"},{"location":"integration/Event-Issuer/terminology/","title":"Event Issuer Terminology","text":"<p>This document contains concise explanations of important terminology found in the event issuer. For more specific information and use cases, read relevant documentation found on the event issuer Wiki.</p> Term Definition Consumer An entity either internal or external to Bane NOR which uses Event Issuer to consume data from the Bane NOR Event Backbone Producer An entity either internal or external to Bane NOR which uses Event Issuer to produce data to the Bane NOR Event Backbone Subscription A generic name used in Event Issuer to explain an active consumer within Event Issuer which continuously fetches data from the Bane NOR Event Backbone and forwards it to a specified webhook endpoint Tenant A Top-level entity representing organizations or more top-level structures. All principals, policies and subscriptions are linked to a tenant although some principals can also manage the tenant Principal A Principal is an object that represents a user, group, or service account. In the initial release mainly service accounts will be supported. Policy A Policy refers to authorization policies that determine which actions principals can take within the Event Issuer eco-system. Common policies would be principal policies for tenants, subscriptions, and events determining their possibility to create new subscriptions, list out subscriptions, delete active subscriptions, produce data, etc."},{"location":"integration/Event-Issuer/terminology/#api-terminology","title":"API Terminology","text":"Term Definition Authentication The process of verifying the identity of a user or system attempting to access an API. Authorization Determines what actions an authenticated user or system can perform. Endpoint A specific URL where the API can receive requests, corresponding to a unique function or resource. Payload The data transmitted in an API request or response in JSON. Status Codes HTTP codes that indicate the result of an API request, such as 200 (success) or 404 (resource not found). Webhook A method for sending real-time data from the API to another system, triggered by an event. Access Token A short-lived token used to access protected API resources, issued during authentication."},{"location":"integration/Event-Issuer/User-Guides/cloudevents/","title":"Cloudevents","text":"<p>The cloudevents specification is used by Event Issuer both for subscribed events and produced events. The difference is how Event Issuer is using the Cloud Events for events being subscribed to and when producing.</p>"},{"location":"integration/Event-Issuer/User-Guides/cloudevents/#subscription","title":"Subscription","text":"<p>Subscribed events are receiving the cloud events by using the HTTP Protocol Binding. This means that the CloudEvents are part of the HTTP headers.</p>"},{"location":"integration/Event-Issuer/User-Guides/cloudevents/#producers","title":"Producers","text":"<p>Producers needs to transmit the CloudEvent metadata by using the JSON Event Format. The produce endpoints expect a content type of <code>application/cloudevents+json</code> as specified in section <code>3. Envelope</code> of the specification.</p>"},{"location":"integration/Event-Issuer/User-Guides/debugging/","title":"Debugging subscriptions","text":"<p>To make the event issuer more self-service, the integration team has set up multiple solutions to allow for as much debugging as possible on the client side before a member of the integration team has to get involved. The main methods recommended for debugging by the integration team are:</p> <ul> <li>Checking subscription status</li> </ul>"},{"location":"integration/Event-Issuer/User-Guides/debugging/#debugging-by-checking-subscription-status","title":"Debugging by checking subscription status","text":"<p>The Event Issuer has built-in Error Reporting linked to the GetSubscription methods. This means that if an error has occurred on your subscription, you can call the GetSubscription method which in case an error has occurred, will return an error report with useful debug information such as:</p> <ul> <li>A relevant Error Message</li> <li>A Trace ID for tracking the error in Grafana</li> <li>A HTTP status code</li> <li>A timestamp for when the error occurred</li> </ul> <p>An example of how this looks in the Bruno API Client is showcased below: (Added when functionality is added)</p>"},{"location":"integration/Event-Issuer/User-Guides/faq/","title":"FAQ","text":"<ul> <li>FAQ<ul> <li>Q: I regenerated my API keys, but i no longer have access</li> <li>Q: I am not allowed to produce an event/topic with event issuer, even though my confluent user has access</li> </ul> </li> </ul> <p>Click on the questions to reveal the answer. If you cant find the answer you are looking for, please let us know by contacting integrasjonsteamet@banenor.no.</p>"},{"location":"integration/Event-Issuer/User-Guides/faq/#q-i-regenerated-my-api-keys-but-i-no-longer-have-access","title":"Q: I regenerated my API keys, but i no longer have access","text":"<p>When you regenerate your API Keys in the API portal, you get new API-keys that are usable for the Event-issuer API found in APIM. However, the new keys are now no longer linked to the policy in Event Issuers Authorization Service, meaning that it will stop you when you try to complete the same actions as before such as CreateSubscription or ProduceEvent. To fix this issue, please get in touch with a member of the integration team.</p>"},{"location":"integration/Event-Issuer/User-Guides/faq/#q-i-am-not-allowed-to-produce-an-eventtopic-with-event-issuer-even-though-my-confluent-user-has-access","title":"Q: I am not allowed to produce an event/topic with event issuer, even though my confluent user has access","text":"<p>When you try to produce data for an event or topic that you have a confluent user for, it will usually allow you to complete the requested action. However, Event-Issuer has an extra authorization layer that also validates that your API-Subscription Keys are allowed to produce data for the specified event. To also get this access, please contact a member of the integration team.</p>"},{"location":"integration/Event-Issuer/User-Guides/getting-started/","title":"Getting Started","text":"<p>The guide contains a quick introduction to how one can get access to and start using the Event Issuer service in Bane NOR.</p> <ul> <li>Getting Started<ul> <li>Getting access<ul> <li>Onboarding</li> <li>Get API Access</li> </ul> </li> <li>Using Event Issuer<ul> <li>Starting your first subscription<ul> <li>Example Bruno Request<ul> <li>Header</li> <li>Body</li> </ul> </li> </ul> </li> <li>Producing your first message<ul> <li>Example Bruno Request<ul> <li>Header</li> <li>Body</li> </ul> </li> </ul> </li> </ul> </li> </ul> </li> </ul>"},{"location":"integration/Event-Issuer/User-Guides/getting-started/#getting-access","title":"Getting access","text":""},{"location":"integration/Event-Issuer/User-Guides/getting-started/#onboarding","title":"Onboarding","text":"<p>The first step in getting access to the event-issuer service is an onboarding meeting with the integration platform. Here the goal is to map out the thought-out use case/cases for your team and why the Event Issuer would be a relevant solution. To start this onboarding process, please contact the integration team on our e-mail: integrasjonsteamet@banenor.no</p> <p>If you are already onboarded and have been allowed to use the Event Issuer Service, the first step below (Get API Access) can be ignored.</p>"},{"location":"integration/Event-Issuer/User-Guides/getting-started/#get-api-access","title":"Get API Access","text":"<p>After permission has been given to use the Event Issuer service, the next step is to get API access to the event-issuer API which is available through the integration team API Management (APIM) instance. For the integration team to be able to provide you with API keys you first have to at least once log into the APIM developer portal relevant to the environment you want to use the Event Issuer in. Here is a list showcasing the possible environments:</p> <ul> <li>For the staging environment: APIM Portal Staging</li> <li>For the production environment: APIM Portal Production</li> </ul> <p>The staging environment can be used to consume data from dev topics. The reason for this is that our dev instance will not necessarily be stable for public use and as such we will serve both dev and staging with the staging event issuer for those that need to work with their own development.</p> <p>Once logged in to the developer portal for the first time, you will be visible with your e-mail address and the integration team will be able to provide you with subscription keys.</p>"},{"location":"integration/Event-Issuer/User-Guides/getting-started/#using-event-issuer","title":"Using Event Issuer","text":"<p>As mentioned in the getting access chapter of this document, the Event Issuer is available through an API present in each environment instance of APIM meaning that all available endpoints and their descriptions can be seen there. The API documentation is also available on GitHub using Redocly rendering which can be easier to read. The document can be seen here: GitHub version of API</p> <p>This means that if you prefer, you can simply test sending API requests using for example Bruno based on the API documentation. Otherwise, here is a showcase of some Bruno requests that can help you get started with links to relevant repositories.</p>"},{"location":"integration/Event-Issuer/User-Guides/getting-started/#starting-your-first-subscription","title":"Starting your first subscription","text":"<p>Once your user has gotten access to the event-issuer API, and a tenant for your organization has been created with the correct access policies, you can create your first subscription. To create a subscription, you must use the Create Subscription method towards the event-issuers subscription Endpoint. The API definition for this can be seen on the available API found in our GitHub documentation here: Create Subscription Method</p>"},{"location":"integration/Event-Issuer/User-Guides/getting-started/#example-bruno-request","title":"Example Bruno Request","text":"<p>An example request for this method can be found in our event issuer repository in our bruno folder or seen in the figure below using the Bruno API client:</p>"},{"location":"integration/Event-Issuer/User-Guides/getting-started/#header","title":"Header","text":"<p>The only required header per writing is the API key for the event-issuer API found on your account in the developer portal </p>"},{"location":"integration/Event-Issuer/User-Guides/getting-started/#body","title":"Body","text":"<p>The content of the request are just for examples. For more concrete information on all subscription body options. Check out the subscriptions page </p>"},{"location":"integration/Event-Issuer/User-Guides/getting-started/#producing-your-first-message","title":"Producing your first message","text":"<p>Once your user has gotten access to the event-issuer API, and a tenant for your organization has been created with the correct access policies, you can produce your first message towards the Bane NOR Event Backbone which as per writing is Confluent Kafka. To produce a message, you must use either the Produce Cloud Event method or Produce batch of Cloud Events  method found under the produce endpoint. The API definition for this can be seen on the available API found in our GitHub documentation here: Produce Cloud Event Method</p>"},{"location":"integration/Event-Issuer/User-Guides/getting-started/#example-bruno-request_1","title":"Example Bruno Request","text":"<p>An example request for this method can be found in our event issuer repository in the bruno folder or seen in the figure below using the Bruno API client:</p>"},{"location":"integration/Event-Issuer/User-Guides/getting-started/#header_1","title":"Header","text":"<p>The only required header per writing is the API key for the event-issuer API found on your account in the developer portal </p>"},{"location":"integration/Event-Issuer/User-Guides/getting-started/#body_1","title":"Body","text":"<p>The content of the request are just for examples </p>"},{"location":"integration/Event-Issuer/User-Guides/producing/","title":"Producing","text":"<p>(For concrete examples, check out our bruno collection)</p> <p>Event Issuer can be used to produce new events into Bane NOR. This is not openly available and an agreement with Bane NOR is needed to be able to produce data. The correct access rights for producing will be given on an agreement basis.</p> <p>Bane NOR uses the Cloud Event specification for producing events and supports producing both single events and the possibility of sending batches of events.</p> <p>Cloud Events has created SDKs for different languages that can be found on the main page under the <code>SDKs</code> in the menu.</p> <p>The Event Issuer has two API endpoints for this:</p> <ul> <li>{tenantId}/produce</li> <li>{tenantId}/produce/batch</li> </ul>"},{"location":"integration/Event-Issuer/User-Guides/producing/#production-modes","title":"Production modes","text":"<p>As mentioned, Event Issuer supports multiple methods for producing data into Bane NOR, both single events and batches. Including this, Event Issuer also supports two different Cloud Event structures, Binary and Structured mode showcased in the chapters below.</p> <p>At the moment only data produced with the JSON format is supported, but other content types can be added later based on user needs.</p>"},{"location":"integration/Event-Issuer/User-Guides/producing/#binary","title":"Binary","text":"<p>In binary mode, the <code>cloud event</code> headers are sent as part of the HTTP header values by using the <code>ce-</code> prefix. For more information about this see the binary mode documented in the specification.</p> <pre><code>POST event-issuer/v1/{tenantId}/produce HTTP/1.1\nHost: api.banenor.com\nce-specversion: 1.0\nce-type: cloud.domain.sub-domain.event.v1\nce-time: 2018-04-05T03:56:24Z\nce-id: 1234-1234-1234\nce-source: /mycontext/subcontext\n .... further attributes ...\nContent-Type: application/json; charset=utf-8\nContent-Length: nnnn\n\n{\n ... application data ...\n}\n</code></pre>"},{"location":"integration/Event-Issuer/User-Guides/producing/#structured","title":"Structured","text":"<p>With structured mode, the <code>cloud event</code> headers are sent as part of the HTTP payload/body data. For more information about this see the structured mode documented in the specification.</p> <pre><code>POST event-issuer/v1/{tenantId}/produce HTTP/1.1\nHost: api.banenor.com\nContent-Type: application/cloudevents+json; charset=utf-8\nContent-Length: nnnn\n\n{\n \"specversion\" : \"1.0\",\n \"type\" : \"cloud.domain.sub-domain.event.v1\",\n\n ... further attributes omitted ...\n\n \"data\" : {\n ... application data ...\n }\n}\n</code></pre>"},{"location":"integration/Event-Issuer/User-Guides/producing/#batch","title":"Batch","text":"<p>With batch mode, a list of cloud events can be sent in one HTTP request to reduce the amount of required API calls. The example showcased here applies structured mode:</p> <pre><code>POST event-issuer/v1/{tenantId}/produce/batch HTTP/1.1\nHost: api.banenor.com\nContent-Type: application/cloudevents-batch+json; charset=utf-8\nContent-Length: nnnn\n\n[\n {\n \"specversion\" : \"1.0\",\n \"type\" : \"cloud.domain.sub-domain.event.v1\",\n\n ... further attributes omitted ...\n\n \"data\" : {\n ... application data ...\n }\n },\n {\n \"specversion\" : \"1.0\",\n \"type\" : \"cloud.domain.sub-domain.event.v2\",\n\n ... further attributes omitted ...\n\n \"data\" : {\n ... application data ...\n }\n }\n]\n</code></pre>"},{"location":"integration/Event-Issuer/User-Guides/subscriptions/","title":"Subscriptions","text":"<p>(For concrete examples, check out our bruno collection)</p> <p>Subscriptions are the main mechanism for getting real-time events from the Bane NOR event backbone. The subscription is a reference to an application that wants events to be sent to a webhook endpoint. The subscriber can configure the authentication towards the endpoint in addition to an API key if that is needed.</p>"},{"location":"integration/Event-Issuer/User-Guides/subscriptions/#webhook-endpoint","title":"Webhook endpoint","text":"<p>The endpoint can receive the event payload with additional metadata by using the CloudEvents HTTP binding.</p> <p>Cloud events are sent by using the HTTP Protocol Binding. This means that the CloudEvents are part of the HTTP headers.</p> <p>Info</p> <p>Bane NOR is working on standardizing event messages around the cloud event specification which means that some event types might be missing from the cloud event headers.</p>"},{"location":"integration/Event-Issuer/User-Guides/subscriptions/#authenticating-subscriptions","title":"Authenticating subscriptions","text":"<p>Some users require authentication and authorization to be able to communicate with their APIs. For this purpose, different types can be configured for the subscription. The following are supported:</p> <ul> <li>No authentication</li> <li>API Key</li> <li>Basicauth</li> <li>OAuth 2.0</li> </ul> <p>The idea is that the end users or services can configure the needed information to authenticate towards the webhook endpoint and update the configuration as needed.</p>"},{"location":"integration/Event-Issuer/User-Guides/subscriptions/#api-key","title":"API Key","text":"<p>API Key is something that is created when subscribing to certain APIs or products. The key can be used both as a token for an API Management system to check if and how the request should be handled, and in monitoring situations to check that the number of requests is within for example rate limits set by the API owner.</p> <p>Event Issuer supports the use of an API Key configuration which can be configured with one of the other authentication mechanisms if both are needed.</p>"},{"location":"integration/Event-Issuer/User-Guides/subscriptions/#basic-auth","title":"Basic Auth","text":"<p>Basic authentication with a username and password is supported as a simple mechanism for getting access to a webhook.</p>"},{"location":"integration/Event-Issuer/User-Guides/subscriptions/#example","title":"Example","text":"<pre><code>{\n\u00a0 \u00a0 \"applicationId\": \"application1\",\n\u00a0 \u00a0 \"eventName\": \"cloud.open.operational.train-arrived-at-station.v1\",\n\u00a0 \u00a0 \"url\": \"https://test.no/test\",\n\u00a0 \u00a0 \"apiKey\": {\n\u00a0 \u00a0 \u00a0 \u00a0 \"header\": \"Ocp-Apim-Subscription-Key\",\n\u00a0 \u00a0 \u00a0 \u00a0 \"key\": \"jnfdi923r8fnaszy12orf98032nrcn7u982\"\n },\n\u00a0 \u00a0 \"authentication\": {\n\u00a0 \u00a0 \u00a0 \u00a0 \"type\": \"BasicAuth\",\n\u00a0 \u00a0 \u00a0 \u00a0 \"username\": \"systemx\",\n\u00a0 \u00a0 \u00a0 \u00a0 \"password\": \"use-a-secure-password\"\n }\n}\n</code></pre>"},{"location":"integration/Event-Issuer/User-Guides/subscriptions/#identity-providers","title":"Identity Providers","text":"<p>An identity provider (IdP) is a system that creates, stores and manages digital identities. The IdP can either directly authenticate the user or can provide authentication services to third-party service providers (apps, websites, or other digital services).</p> <p>The following IdPs are supported for fetching OAuth2.0 tokens:</p> <ul> <li>Maskinporten</li> <li>Entra ID</li> </ul> <p>The following diagram shows the system context for communication with an IdP.</p> <p></p>"},{"location":"integration/Event-Issuer/User-Guides/subscriptions/#maskinporten","title":"Maskinporten","text":"<p>Maskinporten is a Norwegian solution to add authorizations between companies that need to be able to share data between systems or in other words machine-to-machine.</p> <p>Example:</p> <pre><code>{\n\u00a0 \u00a0 \"applicationId\": \"application1\",\n\u00a0 \u00a0 \"eventName\": \"cloud.open.operational.train-arrived-at-station.v1\",\n\u00a0 \u00a0 \"url\": \"https://test.no/test\",\n\u00a0 \u00a0 \"apiKey\": {\n\u00a0 \u00a0 \u00a0 \u00a0 \"header\": \"Ocp-Apim-Subscription-Key\",\n\u00a0 \u00a0 \u00a0 \u00a0 \"key\": \"jnfdi923r8fnaszy12orf98032nrcn7u982\"\n },\n\u00a0 \u00a0 \"authentication\": {\n\u00a0 \u00a0 \u00a0 \u00a0 \"type\": \"Maskinporten\",\n\u00a0 \u00a0 \u00a0 \u00a0 \"scopes\": [ \"company:apix:write\" ]\n }\n}\n</code></pre> <p>Info</p> <p>To be able to use Maskinporten the integration team at Bane NOR needs to be contacted to link the Maskinporten integration to be able to use the correct scope from the API vendor.</p> <p>For companies that use a token exchange where the Maskinporten token needs to be exchanged with a company-specific token, contact the integration team with the specific needs. This will then be added to the backlog and implemented as a tenant-specific solution for those needs.</p>"},{"location":"integration/Event-Issuer/User-Guides/subscriptions/#entra-id","title":"Entra ID","text":"<p>Entra ID is the standard OAuth authentication mechanism used in Azure. To be able to use this with Event Issuer subscriptions, we will need to do a server-to-server interaction that runs in the background, without immediate interaction with a user. This is done through an OAuth client-credential flow that grants permissions directly to the application itself by an administrator.</p> <p>Entra Id also uses the JWT Grant mechanisms to obtain the <code>access_token</code> for requests. These are the configuration options for Entra.</p> <pre><code>// With client secret\n{\n\u00a0 \u00a0 \"AuthUrl\": \"https://login.microsoftonline.com/\",\n\u00a0 \u00a0 \"TenantId\": \"[Enter here the tenantID or domain name for your Azure AD tenant]\",\n\u00a0 \u00a0 \"ClientId\": \"[Enter here the ClientId for your application]\",\n\u00a0 \u00a0 \"ClientSecret\": \"string\",\n\u00a0 \u00a0 \"scope\": \"string\",\n\u00a0 \u00a0 \"grant_type\": \"client_credentials\"\n}\n</code></pre> <pre><code>// With a certificate or federated credential\n{\n\u00a0 \u00a0 \"AuthUrl\": \"https://login.microsoftonline.com/\",\n\u00a0 \u00a0 \"TenantId\": \"[Enter here the tenantID or domain name for your Azure AD tenant]\",\n\u00a0 \u00a0 \"ClientId\": \"[Enter here the ClientId for your application]\",\n\u00a0 \u00a0 \"client_assertion_type\": \"The value must be set to urn:ietf:params:oauth:client-assertion-type:jwt-bearer.\",\n\u00a0 \u00a0 \"client_assertion\": \"JSON web token needed to sign with the certificate\",\n\u00a0 \u00a0 \"scope\": \"string\",\n\u00a0 \u00a0 \"grant_type\": \"client_credentials\"\n}\n</code></pre> <p>Example:</p> <pre><code>{\n\u00a0 \u00a0 \"applicationId\": \"application1\",\n\u00a0 \u00a0 \"eventName\": \"cloud.open.operational.train-arrived-at-station.v1\",\n\u00a0 \u00a0 \"url\": \"https://test.no/test\",\n\u00a0 \u00a0 \"apiKey\": {\n\u00a0 \u00a0 \u00a0 \u00a0 \"header\": \"Ocp-Apim-Subscription-Key\",\n\u00a0 \u00a0 \u00a0 \u00a0 \"key\": \"jnfdi923r8fnaszy12orf98032nrcn7u982\"\n },\n\u00a0 \u00a0 \"authentication\": {\n\u00a0 \u00a0 \u00a0 \u00a0 \"type\": \"EntraId\",\n\u00a0 \u00a0 \u00a0 \u00a0 \"url\": \"https://login.microsoftonline.com/{tenantId}/oauth2/v2.0/token\",\n\u00a0 \u00a0 \u00a0 \u00a0 \"clientId\": \"d0a3da30-8936-4800-9c23-37c1b86d8a63\",\n\u00a0 \u00a0 \u00a0 \u00a0 \"clientSecret\": \"7hzQ3bPSNThb7Cgem+a+w2RqLMKr*LqCSALYco-zQyi4ueUnVo\",\n\u00a0 \u00a0 \u00a0 \u00a0 \"scopes\": [ \"apix:write\" ]\n }\n}\n</code></pre>"},{"location":"integration/Event-Issuer/User-Guides/subscriptions/#client-credentials-flow","title":"Client credentials flow","text":"<p>This diagram describes how authentication works between background services. For Event-Issuer the flow would look like this.</p> <p>This flow assumes that an admin has created an app registration for the subscription and given it the correct permissions to the Web API in question.</p> <pre><code>sequenceDiagram\n participant Event Issuer Subscription\n participant EntraId\n participant Web API\n\n Event Issuer Subscription-&gt;&gt;EntraId: Request token\n EntraId--&gt;&gt;Event Issuer Subscription: Returns token\n loop Until the consumer has caught up to the offset\n Event Issuer Subscription-&gt;&gt;Web API: Posts data to API with a token in Authorization header\n end\n Web API-&gt;&gt;Web API: Validates token\n alt Success\n Web API--&gt;&gt;Event Issuer Subscription: 200 ok\n else Failed\n Web API --&gt;&gt;Event Issuer Subscription: 401, 403, 404, 501, etc.\n end</code></pre>"},{"location":"integration/Event-Issuer/User-Guides/subscriptions/#access-control","title":"Access control","text":"<p>Microsoft provides two options to grant access to applications: access control lists and application permissions.</p>"},{"location":"integration/Event-Issuer/User-Guides/subscriptions/#access-control-lists","title":"Access control lists","text":"<p>Access control lists enforce authorization based on a list of application IDs that it knows and grants a specific level of access to. When the relevant resource receives a token, it decodes it and checks it against the list of authorized clients.</p>"},{"location":"integration/Event-Issuer/User-Guides/subscriptions/#application-permissions","title":"Application permissions","text":"<p>For data owned by organizations, Microsoft recommends using application permissions. To use application roles with your API, you need to expose the app roles in the API's app registration, and then configure the required roles in your client's (the subscription) app registration. The user who creates a subscription will also have to create an app registration in their organization that they provide the necessary permissions.</p>"},{"location":"integration/Event-Issuer/User-Guides/subscriptions/#create-subscription","title":"Create Subscription","text":"<p>The following command can be used to create a subscription that uses an API key and basic authentication.</p> <pre><code>curl -H \"Ocp-Apim-Subscription-Key: ApiKey\" https://&lt;bane-nor-api-endpoint&gt;/event-issuer/v1alpha/{tenantId}/subscriptions -d\n'{\"applicationId\": \"my-application\", \"event\": \"event-name\", \"URL\": \"https://my-endpoint.com/events}, \"apiKey\":\n{ \"header\": \"Ocp-Apim-Subscription-Key\", \"key\": \"API-key\" }, \"authentication\": { \"username\": \"user1\", \"password\": \"my-secure-password\" }'\n</code></pre> <p>If only an API key is needed don't set the <code>authentication</code> and and only the <code>apiKey</code> section.</p>"},{"location":"integration/Event-Issuer/User-Guides/tenants/","title":"Tenants","text":"<p>Warning</p> <p>The following section is under construction</p> <p>Event Issuer uses the concept of Tenants to provide a multi-tenancy architecture around the solution. This gives Bane NOR better control over the resource usage.</p> <p>Tenants can at the moment only be created by Bane NOR.</p>"},{"location":"integration/Event-Issuer/User-Guides/tracing/","title":"Tracing","text":"<p>Event Issuer uses Open Telemetry and will deliver a tracing value for every outgoing event.</p> <p>The standardized way to transmit tracing values is by following the W3 standard by using:</p> <ul> <li><code>traceparent</code> describes the position of the incoming request in its trace graph in a portable, fixed-length format. Its design focuses on fast parsing. Every tracing tool MUST properly set <code>traceparent</code> even when it only relies on vendor-specific information in <code>tracestate</code></li> <li><code>tracestate</code> extends <code>traceparent</code> with vendor-specific data represented by a set of name/value pairs. Storing information in <code>tracestate</code> is optional.</li> </ul>"},{"location":"integration/Event-Issuer/apis/v1/","title":"Event Issuer API spec","text":"<p>hide:   #- navigation - toc</p> <p></p>"},{"location":"integration/Payload-Manager/","title":"Payload Manager","text":"<ul> <li>Payload Manager<ul> <li>General Overview</li> <li>Rollout phases</li> </ul> </li> </ul> <p>Payload Manager is a service supported by the Integration Team for handling file transfer between services. This solves the <code>claim check pattern</code> where services can upload a file to a managed storage container and a claim check event is generated onto a Kafka topic. Other systems can then subscribe to said Kafka topic, receive information when a new file is available, and download the file themselves from the storage account.</p> <p>Services <code>should</code> use the Confluent Platform for async communications, but as a way of working towards this goal, the Payload Manager can be used as a temporary solution. There might also be cases where it is not possible to use Kafka as the main way of transferring data, for example, if large pictures or video files need to be moved. For these cases, the Payload Manager can be used as the main solution for moving data.</p> <p>Start using the payload manager</p>","tags":["integration","payload-manager"]},{"location":"integration/Payload-Manager/#general-overview","title":"General Overview","text":"<p>A general overview of the <code>claim check</code> pattern in Bane NOR:</p> <p></p>","tags":["integration","payload-manager"]},{"location":"integration/Payload-Manager/#rollout-phases","title":"Rollout phases","text":"<p>The development of the payload manager is split into 3 phases, where each phase adds more functionality. The order of the list showcases the priority of implementation:</p> Phase Implemented Internal file share External file share Transfer between KV IKT and Enterprise IT","tags":["integration","payload-manager"]},{"location":"integration/Payload-Manager/Getting-Started/","title":"Getting Started","text":"<p>The goal of this guide is to give a quick introduction to how one can get access to and start using the Payload Manager in BaneNOR.</p> <ul> <li>Getting Started<ul> <li>Onboarding</li> <li>Domain for Storage Account Container<ul> <li>Existing Domains</li> </ul> </li> <li>Using the Payload Manager<ul> <li>Accessing the Payload Manager</li> </ul> </li> <li>API Management DNS</li> </ul> </li> </ul>","tags":["integration","payload-manager","API","blobs","storage"]},{"location":"integration/Payload-Manager/Getting-Started/#onboarding","title":"Onboarding","text":"<p>The first step in getting access to the payload-manager service is an onboarding meeting with the integration platform. Here the goal is to map out the thought-out use case/cases for your team and why the Payload Mangager would be a relevant solution. To start this onboarding process, you should have talked with your BaneNOR collaborators who should take care of the onboarding.</p> <p>If you are already onboarded and have been allowed to use the Payload Manager Service, the first step can be ignored.</p>","tags":["integration","payload-manager","API","blobs","storage"]},{"location":"integration/Payload-Manager/Getting-Started/#domain-for-storage-account-container","title":"Domain for Storage Account Container","text":"<p>Our storage accounts used for the payload manager are divided into containers based on separate domains. Each domain has its own Kafka topic.</p>","tags":["integration","payload-manager","API","blobs","storage"]},{"location":"integration/Payload-Manager/Getting-Started/#existing-domains","title":"Existing Domains","text":"<p>If your domain is already set up within the payload manager, we simply need to grant you the necessary permissions to start using it.</p>","tags":["integration","payload-manager","API","blobs","storage"]},{"location":"integration/Payload-Manager/Getting-Started/#using-the-payload-manager","title":"Using the Payload Manager","text":"<p>Once you have access to the appropriate domain within the storage account, you can use the API to upload and download blobs. For more information, refer to Skyporten.</p>","tags":["integration","payload-manager","API","blobs","storage"]},{"location":"integration/Payload-Manager/Getting-Started/#accessing-the-payload-manager","title":"Accessing the Payload Manager","text":"<p>Our storage account utilizes Microsoft's standard API, with support from microsoft libraries, making it easy to setup your custom applications for uploading and downloading blobs to the payload-manager storage accounts. For external users, Skyporten has to be used in conjunction.</p> <p>Listening to the payload-manager topic for your domain can be done with</p> <ol> <li>Event Issuer: Use the Event Issuer API to listen to the payload-manager topic.</li> </ol>","tags":["integration","payload-manager","API","blobs","storage"]},{"location":"integration/Payload-Manager/Getting-Started/#api-management-dns","title":"API Management DNS","text":"<p>We have different API Management instances depending on the environment you will be using.</p> Environment DNS Dev https://dev.api.apps.banenor.no Test/Staging https://test.api.apps.banenor.no Prod https://api.banenor.no","tags":["integration","payload-manager","API","blobs","storage"]},{"location":"integration/Payload-Manager/Getting-Started/File-and-blob-restrictions/","title":"File and blob restrictions","text":"<p>To ensure the security and quality of our file storage, we have implemented policies on the storage account API to restrict certain files.</p>","tags":["integration","payload-manager","API","blobs","storage","restrictions","policies"]},{"location":"integration/Payload-Manager/Getting-Started/File-and-blob-restrictions/#file-retention","title":"File Retention","text":"<p>Files stored inside the payload manager storage accounts will be kept for a standard of 8 days from creation. This is per our Kafka message retention policy of 7 days + 1.</p>","tags":["integration","payload-manager","API","blobs","storage","restrictions","policies"]},{"location":"integration/Payload-Manager/Getting-Started/File-and-blob-restrictions/#file-type-restriction","title":"File type restriction","text":"<p>To limit potentially dangerous files, we keep a whitelist of allowed file types listed in the table below. If you need to upload a file type not in this list, please contact the integration team.</p> Category Allowed file types Text files .txt .csv .log .json .xml .md Images .jpg .jpeg .png .gif .bmp .tiff .webp Audio &amp; Video .mp3 .wav .mp4 .avi .mov .flac Office Documents .pdf .doc .docx .xls .xlsx .ppt .pptx Archives .zip .tar .gz .rar Code Files .html .css .js .py .cs Other .vp0 .vspe .kmm .kmm2 .bmp .hdr","tags":["integration","payload-manager","API","blobs","storage","restrictions","policies"]},{"location":"integration/Payload-Manager/Getting-Started/File-and-blob-restrictions/#file-size-restriction","title":"File Size Restriction","text":"<p>We currently limit each request towards storage to 100 mb per request. This is a limit set to ensure only reasonably large files are uploaded to the storage account. When uploading larger files, they have to be uploaded in multiple blocks.</p>","tags":["integration","payload-manager","API","blobs","storage","restrictions","policies"]},{"location":"integration/Payload-Manager/Getting-Started/File-and-blob-restrictions/#file-name-restrictions","title":"File name restrictions","text":"<p>To prevent path traversal, other dangers, and programmatic errors, we have put restrictions on names allowed to be uploaded to the storage account. This restriction follows the regex <code>[a-zA-Z0-9.-]</code>.</p>","tags":["integration","payload-manager","API","blobs","storage","restrictions","policies"]},{"location":"integration/Payload-Manager/Getting-Started/File-and-blob-restrictions/#examples","title":"Examples","text":"Filename Allowed/Disallowed kj\u00f8rebok.xlsx Disallowed kjorebok.xlsx Allowed ola\u00b4s-reisebok.txt Disallowed olas-reisebok.txt Allowed","tags":["integration","payload-manager","API","blobs","storage","restrictions","policies"]},{"location":"integration/Payload-Manager/Getting-Started/Skyporten/","title":"Skyporten","text":"<p>Under construction</p> <p>Skyporten is a service from DigDir, created to allow Norwegian companies to share data between themselves using MaskinPorten as an external iDP token provider and exchanging said token with your own cloud environment such as GCP, Azure, or AWS. A detailed drawing from DigDir showcasing the flow can be seen from DigDirs documentation.</p>","tags":["integration","payload-manager","API","blobs","storage","skyporten","access"]},{"location":"integration/Payload-Manager/Getting-Started/Skyporten/#what-does-the-integration-platform-provide","title":"What does the Integration Platform provide","text":"","tags":["integration","payload-manager","API","blobs","storage","skyporten","access"]},{"location":"integration/Payload-Manager/Getting-Started/Skyporten/#api","title":"API","text":"<p>The Integration Platform provides an API in Maskinporten and provides access to this API through an organization number.</p>","tags":["integration","payload-manager","API","blobs","storage","skyporten","access"]},{"location":"integration/Payload-Manager/Getting-Started/Skyporten/#managed-identity-with-federated-credential","title":"Managed Identity with Federated Credential","text":"<p>The second resouce the Integration Platform provides is a managed identity for external parties. This managed identity will be used as your identity in our cloud IDP solution, EntraID.</p>","tags":["integration","payload-manager","API","blobs","storage","skyporten","access"]},{"location":"integration/Payload-Manager/User-Guides/Uploading-and-downloading-files/","title":"Uploading and Downloading files","text":"<p>Under construction</p> <p>The following guide will show you how you can start uploading or downloading files from storage.</p>","tags":["integration","payload-manager","API","blobs","storage","guide",".NET","C#"]},{"location":"integration/Payload-Manager/User-Guides/Uploading-and-downloading-files/#dependencies","title":"Dependencies","text":"<p>The blob store (storage container) is accessible from API Management which is just a proxy in front of a Storage Account. To be able to upload and download files the service needs an Entra identity with correct access to the blob store. This will be granted to external parties through Skyporten</p> <p>Since it is just a proxy for the Microsoft API the Nuget packages created by Microsoft can be used as is. An example can be found here: Microsoft blob storage Nuget Package</p>","tags":["integration","payload-manager","API","blobs","storage","guide",".NET","C#"]},{"location":"integration/Payload-Manager/User-Guides/Uploading-and-downloading-files/#nuget","title":"Nuget","text":"<p>To be able to use the Payload Manager, the following Nuget packages are needed:</p> <p>Global Nuget Packages:</p> <ul> <li>Azure.Identity</li> <li>Azure.Storage.Blobs</li> <li>Microsoft.Extensions.Azure</li> </ul>","tags":["integration","payload-manager","API","blobs","storage","guide",".NET","C#"]},{"location":"integration/Payload-Manager/User-Guides/Uploading-and-downloading-files/#confluent-access","title":"Confluent Access","text":"<p>Event Issuer will also needs access to the <code>cloud.&lt;environment&gt;.internal.payload-manager.&lt;container-name&gt;.claim-check.blob.v1</code> topic and the schemas registered to the topic. These topics are dependent on schemas and as such consumers need to use the schema serializer to be able to deserialize messages read from this topic.</p>","tags":["integration","payload-manager","API","blobs","storage","guide",".NET","C#"]},{"location":"integration/Payload-Manager/User-Guides/Uploading-and-downloading-files/#easy-aspnet-programcs","title":"Easy ASP.NET program.cs","text":"<p>The example below showcases a minimal C# program for uploading and downloading a file using the payload manager storage account API. More in-depth examples can be seen in Microsoft documentation linked to at the top of this article.</p> <pre><code>using Azure.Identity;\nusing Azure.Storage.Blobs;\nusing Microsoft.AspNetCore.Mvc;\nusing Microsoft.Extensions.Azure;\n\nvar builder = WebApplication.CreateBuilder(args);\n\nbuilder.Services.AddAzureClients(azClientBuilder =&gt;\n{\n    azClientBuilder.AddBlobServiceClient(new Uri(\"https://dev.api.apps.banenor.no/payload-manager/v1/\"));\n    azClientBuilder.UseCredential(new DefaultAzureCredential());\n});\n\nvar app = builder.Build();\n\napp.MapGet(\"/\", ([FromServices] BlobServiceClient blobServiceClient) =&gt;\n{\n    var blobContainer = blobServiceClient.GetBlobContainerClient(\"integration-dev\");\n    \n    using var stream = File.OpenRead(@\"appsettings.json\");\n    \n    var blobClient = \n        blobContainer.GetBlobClient(\"v1/integration-dev/appsettings.json\");  \n\n    # Microsoft SDK is not setting the correct URL for the blob container so we \n    # need to add the \"v1/&lt;container-name&gt;/&lt;file-path-and-file&gt;\" \n    # as part of the blob name.\n\n    blobClient.Upload(stream);\n\n    using var stream2 = File.OpenWrite(@\"appsettings2.json\");\n    var file = blobClient.DownloadTo(stream2);\n    return blobContainer.GetBlobs();\n});\n\napp.Run();\n</code></pre>","tags":["integration","payload-manager","API","blobs","storage","guide",".NET","C#"]},{"location":"integration/Payload-Manager/User-Guides/Uploading-and-downloading-files/#upload-with-skyporten","title":"Upload with Skyporten","text":"<pre><code>using Azure.Identity;  \nusing Azure.Storage.Blobs;  \nusing dotnet_payload_manager_skyporten_poc;  \n  \nvar maskinPortenOptions = new MaskinportenOptions()  \n{  \n    ClientId = \"182410a3-0c27-4193-a89b-551be7e38389\",   \n    Audience = \"https://test.sky.maskinporten.no\",  \n    KeyId = \"712f59034deb24013f81\",  \n    Url = new Uri(\"https://test.sky.maskinporten.no/token\"),  \n};  \n  \nvar httpClient = new HttpClient();  \n  \nvar tokenGenerator = new TokenGenerator(maskinPortenOptions, httpClient);  \n\n// Returns bearer token from MaskinPorten  \nvar header = await tokenGenerator.GetAuthenticationHeaderValueAsync();  \n  \nvar tenantId = \"6ee535f2-3064-4ac9-81d8-4ceb2ff790c6\";  \nvar clientId = \"be433565-d4aa-4d0b-b588-1ac539047082\";  \nvar tokenPath = \"/tmp/maskinporten-token.txt\";  \nawait File.WriteAllTextAsync(tokenPath, header.Parameter);  \n  \nvar workLoadIdentityOption = new WorkloadIdentityCredentialOptions()  \n{  \n    TenantId = tenantId,  \n    ClientId = clientId,  \n    TokenFilePath = tokenPath  \n};  \n  \nvar workLoadIdentity = new WorkloadIdentityCredential(workLoadIdentityOption);  \n\n\n// Blob interactions  \nvar blobClientOptions = new BlobClientOptions();  \n  \nvar blobServiceClient = new BlobServiceClient(  \n    new Uri(\"https://dev.api.apps.banenor.no/payload-manager/v1\"), workLoadIdentity, blobClientOptions);  \n\nstring containerName = \"integration-dev\";  \n  \nvar containerClient = blobServiceClient.GetBlobContainerClient(containerName);  \n  \n// Create a local file in the ./data/ directory for uploading and downloading  \nstring localPath = \"data\";  \nDirectory.CreateDirectory(localPath);  \nstring fileName = \"quickstart\" + Guid.NewGuid().ToString() + \".txt\";  \nstring localFilePath = Path.Combine(localPath, fileName);  \n  \nawait File.WriteAllTextAsync(localFilePath, \"Hello, World!\");  \n  \nBlobClient blobClient = containerClient.GetBlobClient(\"v1/integration-dev/path/to/folder/\" + fileName);  \n  \nawait blobClient.UploadAsync(localFilePath, false);  \n</code></pre>","tags":["integration","payload-manager","API","blobs","storage","guide",".NET","C#"]}]}