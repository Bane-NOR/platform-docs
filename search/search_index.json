{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Bane NOR External DocumentationWelcome to the Portal!","text":"<p>Welcome to the Bane NOR External Documentation portal! This centralized resource is designed to streamline your access to user guides, FAQs, best practices, and other relevant documentation essential for external users. This portal is your single source of truth for integrating with BaneNOR's platform services.</p> <p>The content is curated for a technical audience, including developers, system architects, and technical specialists working on Bane NOR's three service platforms: Development Platform, Integration Platform, and Data Platform. By consolidating information previously scattered across multiple wikis, we aim to save time, eliminate confusion, and enhance productivity.</p>"},{"location":"#how-to-navigate","title":"How to Navigate","text":"<p>To ensure ease of use, the documentation is organized into three main sections, each dedicated to one of Bane NOR's service platforms:</p> <ol> <li>Integration Platform: Resources for connecting and integrating systems seamlessly.</li> </ol> <p>Each section contains categorized articles, FAQs, and troubleshooting guides, making it easy to find the information relevant to your needs. Additionally, a global search function indexes all content across platforms, so you can locate any document or guide quickly without needing to know where it resides.</p>"},{"location":"#ownership-and-support","title":"Ownership and Support","text":"<p>The portal is maintained and owned by the Data and Development Platform Team. If you encounter issues, have feedback, or need assistance, feel free to reach out to us via Data and Development Platform.</p> <p>Your feedback helps us improve! Let us know how we can enhance your experience or add value to the documentation.</p> <p>This page serves as your gateway to the knowledge base that drives Bane NOR's development, integration, and data services. Explore, learn, and build confidently!</p>"},{"location":"integration/Payload-Manager/","title":"Payload Manager","text":"<ul> <li>Payload Manager<ul> <li>General Overview</li> <li>Rollout phases</li> </ul> </li> </ul> <p>Payload Manager is a service supported by the Integration Team for handling file transfer between services. This solves the <code>claim check pattern</code> where services can upload a file to a managed storage container and a claim check event is generated onto a Kafka topic. Other systems can then subscribe to said Kafka topic, receive information when a new file is available, and download the file themselves from the storage account.</p> <p>Services <code>should</code> use the Confluent Platform for async communications, but as a way of working towards this goal, the Payload Manager can be used as a temporary solution. There might also be cases where it is not possible to use Kafka as the main way of transferring data, for example, if large pictures or video files need to be moved. For these cases, the Payload Manager can be used as the main solution for moving data.</p> <p>Start using the payload manager</p>","tags":["integration","payload-manager"]},{"location":"integration/Payload-Manager/#general-overview","title":"General Overview","text":"<p>A general overview of the <code>claim check</code> pattern in Bane NOR:</p> <p></p> <p>For more specific documentation with more detailed drawings, please check out our Architecture diagram.</p>","tags":["integration","payload-manager"]},{"location":"integration/Payload-Manager/#rollout-phases","title":"Rollout phases","text":"<p>The development of the payload manager is split into 3 phases, where each phase adds more functionality. The order of the list showcases the priority of implementation:</p> Phase Implemented Internal file share External file share Transfer between KV IKT and Enterprise IT","tags":["integration","payload-manager"]},{"location":"integration/Payload-Manager/Getting-Started/","title":"Getting Started","text":"<p>tags:</p> <ul> <li>integration</li> <li>payload-manager</li> <li>API</li> <li>blobs</li> <li>storage</li> </ul> <p>The goal of this guide is to give a quick introduction to how one can get access to and start using the Payload Manager in BaneNOR.</p> <ul> <li>Getting Started<ul> <li>Onboarding</li> <li>Domain for Storage Account Container<ul> <li>Existing Domains</li> </ul> </li> <li>Using the Payload Manager<ul> <li>Accessing the Payload Manager</li> </ul> </li> <li>Folder Access Control</li> <li>API Management DNS</li> </ul> </li> </ul>"},{"location":"integration/Payload-Manager/Getting-Started/#onboarding","title":"Onboarding","text":"<p>The first step in getting access to the payload-manager service is an onboarding meeting with the integration platform. Here the goal is to map out the thought-out use case/cases for your team and why the Payload Mangager would be a relevant solution. To start this onboarding process, you should have talked with your BaneNOR collaborators who should take care of the onboarding.</p> <p>If you are already onboarded and have been allowed to use the Payload Manager Service, the first step can be ignored.</p>"},{"location":"integration/Payload-Manager/Getting-Started/#domain-for-storage-account-container","title":"Domain for Storage Account Container","text":"<p>Our storage accounts used for the payload manager are divided into containers based on separate domains. Each domain has its own Kafka topic.</p>"},{"location":"integration/Payload-Manager/Getting-Started/#existing-domains","title":"Existing Domains","text":"<p>If your domain is already set up within the payload manager, we simply need to grant you the necessary permissions to start using it.</p>"},{"location":"integration/Payload-Manager/Getting-Started/#using-the-payload-manager","title":"Using the Payload Manager","text":"<p>Once you have access to the appropriate domain within the storage account, you can use the API to upload and download blobs. For more information, refer to API and Access Control.</p>"},{"location":"integration/Payload-Manager/Getting-Started/#accessing-the-payload-manager","title":"Accessing the Payload Manager","text":"<p>Our storage account utilizes Microsoft's standard API, with support from microsoft libraries, making it easy to setup your custom applications for uploading and downloading blobs to the payload-manager storage accounts. For external users, Skyporten has to be used in conjunction.</p> <p>Listening to the payload-manager topic for your domain can be done with</p> <ol> <li>Event Issuer: Use the Event Issuer API to listen to the payload-manager topic.</li> <li>Direct Or listen directly to the payload-manager topic. For this we need to grant read-access to your confluent user</li> </ol>"},{"location":"integration/Payload-Manager/Getting-Started/#folder-access-control","title":"Folder Access Control","text":"<p>We have decided to enable Folder Access Control for the payload-manager storage accounts, which means that the owner of every container can control read / write / execute perissions for folders inside the container, read more about how this works and how to use it here</p> <p>If you have any questions or need further assistance, feel free to reach out!</p>"},{"location":"integration/Payload-Manager/Getting-Started/#api-management-dns","title":"API Management DNS","text":"<p>We have different API Management instances depending on the environment you will be using.</p> Environment DNS Dev https://dev.api.apps.banenor.no Test/Staging https://test.api.apps.banenor.no Prod https://api.banenor.no"},{"location":"integration/Payload-Manager/Getting-Started/Skyporten/","title":"Skyporten","text":"<p>Skyporten is a service from DigDir, created to allow Norwegian companies to share data between themselves using MaskinPorten as an external iDP token provider and exchanging said token with your own cloud environment such as GCP, Azure, or AWS. A detailed drawing from DigDir showcasing the flow can be seen from DigDirs documentation.</p> <p>tags:</p> <ul> <li>integration</li> <li>payload-manager</li> <li>API</li> <li>blobs</li> <li>storage</li> <li>skyporten</li> <li>access</li> </ul>"},{"location":"integration/Payload-Manager/Getting-Started/Skyporten/#what-does-the-integration-platform-provide","title":"What does the Integration Platform provide","text":""},{"location":"integration/Payload-Manager/Getting-Started/Skyporten/#api","title":"API","text":"<p>The Integration Platform provides an API in Maskinporten and provides access to this API through an organization number.</p>"},{"location":"integration/Payload-Manager/Getting-Started/Skyporten/#managed-identity-with-federated-credential","title":"Managed Identity with Federated Credential","text":"<p>The second resouce the Integration Platform provides is a managed identity for external parties. This managed identity will be used as your identity in our cloud IDP solution, EntraID.</p>"},{"location":"integration/Payload-Manager/User-Guides/Uploading-and-downloading-files/","title":"Uploading and Downloading files","text":"<p>The following guide will show you how you can start uploading or downloading files from storage.</p> <p>tags:</p> <ul> <li>integration</li> <li>payload-manager</li> <li>API</li> <li>blobs</li> <li>storage</li> <li>guide</li> </ul>"},{"location":"integration/Payload-Manager/User-Guides/Uploading-and-downloading-files/#dependencies","title":"Dependencies","text":"<p>The blob store (storage container) is accessible from API Management which is just a proxy in front of a Storage Account. To be able to upload and download files the service needs an Entra identity with correct access to the blob store. This will be granted to external parties through Skyporten</p> <p>Since it is just a proxy for the Microsoft API the Nuget packages created by Microsoft can be used as is. An example can be found here: Microsoft blob storage Nuget Package</p>"},{"location":"integration/Payload-Manager/User-Guides/Uploading-and-downloading-files/#nuget","title":"Nuget","text":"<p>To be able to use the Payload Manager, the following Nuget packages are needed:</p> <p>Global Nuget Packages:</p> <ul> <li>Azure.Identity</li> <li>Azure.Storage.Blobs</li> <li>Microsoft.Extensions.Azure</li> </ul>"},{"location":"integration/Payload-Manager/User-Guides/Uploading-and-downloading-files/#confluent-access","title":"Confluent Access","text":"<p>Event Issuer will also needs access to the <code>cloud.&lt;environment&gt;.internal.payload-manager.&lt;container-name&gt;.claim-check.blob.v1</code> topic and the schemas registered to the topic. These topics are dependent on schemas and as such consumers need to use the schema serializer to be able to deserialize messages read from this topic.</p>"},{"location":"integration/Payload-Manager/User-Guides/Uploading-and-downloading-files/#easy-aspnet-programcs","title":"Easy ASP.NET program.cs","text":"<p>The example below showcases a minimal C# program for uploading and downloading a file using the payload manager storage account API. More in-depth examples can be seen in Microsoft documentation linked to at the top of this article.</p> <pre><code>using Azure.Identity;\nusing Azure.Storage.Blobs;\nusing Microsoft.AspNetCore.Mvc;\nusing Microsoft.Extensions.Azure;\n\nvar builder = WebApplication.CreateBuilder(args);\n\nbuilder.Services.AddAzureClients(azClientBuilder =&gt;\n{\n    azClientBuilder.AddBlobServiceClient(new Uri(\"https://dev.api.apps.banenor.no/payload-manager/v1/\"));\n    azClientBuilder.UseCredential(new DefaultAzureCredential());\n});\n\nvar app = builder.Build();\n\napp.MapGet(\"/\", ([FromServices] BlobServiceClient blobServiceClient) =&gt;\n{\n    var blobContainer = blobServiceClient.GetBlobContainerClient(\"integration-dev\");\n    \n    using var stream = File.OpenRead(@\"appsettings.json\");\n    \n    var blobClient = \n        blobContainer.GetBlobClient(\"v1/integration-dev/appsettings.json\");  \n\n    # Microsoft SDK is not setting the correct URL for the blob container so we \n    # need to add the \"v1/&lt;container-name&gt;/&lt;file-path-and-file&gt;\" \n    # as part of the blob name.\n\n    blobClient.Upload(stream);\n\n    using var stream2 = File.OpenWrite(@\"appsettings2.json\");\n    var file = blobClient.DownloadTo(stream2);\n    return blobContainer.GetBlobs();\n});\n\napp.Run();\n</code></pre>"}]}